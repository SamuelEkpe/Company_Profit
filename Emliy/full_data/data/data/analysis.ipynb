{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download, merge, and describe the dataset and its basic characteristics (e.g., shape,\n",
    "variable types, basic stats).\n",
    "2. Choose several variables and create visualizations to show their distributions. Justify\n",
    "your variable selection.\n",
    "3. Clean the dataset to handle any missing data and justify your decisions.\n",
    "4. For building a model, would you rescale any data in this dataset? How and why or\n",
    "why not?\n",
    "5. Build a model to identify risk factors for diabetes. Explain your choice of model and\n",
    "what it can predict. What metrics would you use to assess performance? For this\n",
    "dataset, how would you know your model is adequate?\n",
    "6. Using these data, what are some identifiable risk factors for diabetes? How do you\n",
    "know? Explain as if you were reporting the results to a non-technical stakeholder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Import libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "\n",
    "# Import libraries for building linear regression model\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import library for preparing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import library for data preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max(df, do_print=True):\n",
    "    ranges = [\n",
    "        {\"name\": col, \"min\": df[col].min(), \"max\": df[col].max()} for col in df.columns\n",
    "    ]\n",
    "\n",
    "    if do_print:\n",
    "        print(ranges)\n",
    "\n",
    "    else:\n",
    "        return ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = pd.read_csv(\"dataCategorical.csv\")\n",
    "dn = pd.read_csv(\"dataNumeric.csv\")\n",
    "do = pd.read_csv(\"dataOrdinal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicate columns\n",
    "\n",
    "dc.drop(columns=[\"DIABETE3.1\" ,\"MARITAL.1\"], inplace=True) # these may not be duplicate variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   PERSONID  5000 non-null   int64  \n",
      " 1   DIABETE3  5000 non-null   float64\n",
      " 2   _RACE     4997 non-null   float64\n",
      " 3   MSCODE    3187 non-null   float64\n",
      " 4   FLUSHOT6  4762 non-null   float64\n",
      " 5   EMPLOY1   4981 non-null   float64\n",
      " 6   SEX       5000 non-null   float64\n",
      " 7   MARITAL   4990 non-null   float64\n",
      " 8   CVDCRHD4  5000 non-null   float64\n",
      " 9   HLTHCVR1  3318 non-null   float64\n",
      " 10  CHCKIDNY  5000 non-null   float64\n",
      " 11  USEEQUIP  4837 non-null   float64\n",
      " 12  _TOTINDA  5000 non-null   float64\n",
      " 13  ADDEPEV2  5000 non-null   float64\n",
      " 14  RENTHOM1  4898 non-null   float64\n",
      " 15  EXERANY2  5000 non-null   float64\n",
      " 16  BLIND     4830 non-null   float64\n",
      " 17  DECIDE    4829 non-null   float64\n",
      " 18  HLTHPLN1  5000 non-null   float64\n",
      " 19  _STATE    5000 non-null   float64\n",
      " 20  ASTHMA3   5000 non-null   float64\n",
      "dtypes: float64(20), int64(1)\n",
      "memory usage: 820.4 KB\n"
     ]
    }
   ],
   "source": [
    "dc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analsying the frequency of resonponses on Health Care Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    4621\n",
       "2.0     359\n",
       "9.0      12\n",
       "7.0       8\n",
       "Name: HLTHPLN1, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc[\"HLTHPLN1\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving the names of the dc columns\n",
    "\n",
    "dcColumnsNames = dc.columns.tolist()\n",
    "dnColumnNames = dn.columns.tolist()\n",
    "doColumnNames = do.columns.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the Categorical Data\n",
    "\n",
    "\n",
    "Replacing the NA rows in all  columns with the mean value of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "\n",
    "dc['MSCODE'].fillna(value =dc['MSCODE'].mean(), inplace =True)\n",
    "dc['HLTHCVR1'].fillna(value =dc['HLTHCVR1'].mean(), inplace =True)\n",
    "\n",
    "dc['FLUSHOT6'].fillna(value =dc['FLUSHOT6'].mean(), inplace =True)\n",
    "\n",
    "dc['_RACE'].fillna(value =dc['_RACE'].mean(), inplace =True)\n",
    "\n",
    "dc['EMPLOY1'].fillna(value =dc['EMPLOY1'].mean(), inplace =True)\n",
    "dc['MARITAL'].fillna(value =dc['MARITAL'].mean(), inplace =True)\n",
    "dc['USEEQUIP'].fillna(value =dc['USEEQUIP'].mean(), inplace =True)\n",
    "dc['RENTHOM1'].fillna(value =dc['RENTHOM1'].mean(), inplace =True)\n",
    "dc['BLIND'].fillna(value =dc['BLIND'].mean(), inplace =True)\n",
    "dc['DECIDE'].fillna(value =dc['DECIDE'].mean(), inplace =True)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# replacing NA with the middle occuring value in each column.\n",
    "for column in dcColumnsNames:\n",
    "    dc[column].fillna(value =dc[column].median(), inplace =True)\n",
    "    \n",
    "for column in dnColumnNames:\n",
    "    dn[column].fillna(value =dn[column].median(), inplace =True)\n",
    "    \n",
    "for column in doColumnNames:\n",
    "    do[column].fillna(value =do[column].median(), inplace =True)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIABETE3</th>\n",
       "      <th>_RACE</th>\n",
       "      <th>MSCODE</th>\n",
       "      <th>FLUSHOT6</th>\n",
       "      <th>EMPLOY1</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>CVDCRHD4</th>\n",
       "      <th>HLTHCVR1</th>\n",
       "      <th>CHCKIDNY</th>\n",
       "      <th>...</th>\n",
       "      <th>DRVISITS</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>INCOME2</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>SLEPTIM1</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>_SMOKER3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERSONID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>355467</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117235</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268614</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332821</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348522</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369924</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229177</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264514</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98374</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112601</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334663</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464529</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296926</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63183</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332946</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9756</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240811</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365554</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446372</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377079</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DIABETE3  _RACE  MSCODE  FLUSHOT6  EMPLOY1  SEX  MARITAL  CVDCRHD4  \\\n",
       "PERSONID                                                                       \n",
       "355467         3.0    2.0     3.0       2.0      1.0  1.0      6.0       2.0   \n",
       "117235         3.0    1.0     5.0       1.0      7.0  2.0      3.0       2.0   \n",
       "268614         3.0    1.0     1.0       1.0      7.0  2.0      3.0       2.0   \n",
       "332821         3.0    4.0     3.0       2.0      1.0  1.0      1.0       2.0   \n",
       "348522         3.0    1.0     3.0       1.0      1.0  2.0      1.0       2.0   \n",
       "369924         3.0    1.0     1.0       2.0      7.0  2.0      3.0       2.0   \n",
       "229177         3.0    1.0     3.0       1.0      1.0  1.0      1.0       2.0   \n",
       "264514         3.0    1.0     5.0       2.0      1.0  2.0      1.0       2.0   \n",
       "98374          3.0    9.0     5.0       2.0      7.0  2.0      1.0       2.0   \n",
       "112601         3.0    1.0     1.0       2.0      1.0  2.0      3.0       2.0   \n",
       "334663         3.0    1.0     1.0       2.0      7.0  2.0      1.0       2.0   \n",
       "464529         3.0    8.0     3.0       2.0      1.0  1.0      5.0       2.0   \n",
       "296926         3.0    1.0     2.0       1.0      1.0  2.0      1.0       2.0   \n",
       "63183          3.0    1.0     3.0       2.0      2.0  1.0      1.0       2.0   \n",
       "332946         3.0    1.0     3.0       1.0      1.0  1.0      1.0       2.0   \n",
       "9756           3.0    1.0     5.0       1.0      7.0  2.0      3.0       1.0   \n",
       "240811         3.0    1.0     1.0       2.0      7.0  1.0      1.0       2.0   \n",
       "365554         3.0    2.0     3.0       2.0      8.0  1.0      4.0       2.0   \n",
       "446372         3.0    1.0     1.0       2.0      7.0  1.0      1.0       2.0   \n",
       "377079         3.0    1.0     5.0       1.0      8.0  2.0      2.0       2.0   \n",
       "\n",
       "          HLTHCVR1  CHCKIDNY  ...  DRVISITS  GENHLTH  _AGEG5YR  _BMI5CAT  \\\n",
       "PERSONID                      ...                                          \n",
       "355467         7.0       2.0  ...       6.0      1.0       6.0       3.0   \n",
       "117235         2.0       2.0  ...       2.0      1.0      10.0       3.0   \n",
       "268614         3.0       2.0  ...       2.0      2.0      12.0       2.0   \n",
       "332821         2.0       2.0  ...       4.0      2.0       3.0       2.0   \n",
       "348522         1.0       2.0  ...       1.0      2.0       9.0       2.0   \n",
       "369924         2.0       2.0  ...       4.0      3.0      12.0       2.0   \n",
       "229177         2.0       2.0  ...       4.0      1.0       8.0       4.0   \n",
       "264514         1.0       2.0  ...       5.0      2.0       7.0       2.0   \n",
       "98374          3.0       2.0  ...       2.0      4.0      10.0       3.0   \n",
       "112601         2.0       2.0  ...       4.0      2.0       9.0       3.0   \n",
       "334663         2.0       2.0  ...       4.0      3.0      12.0       2.0   \n",
       "464529         4.0       2.0  ...       1.0      3.0       4.0       4.0   \n",
       "296926         1.0       2.0  ...       7.0      2.0       8.0       2.0   \n",
       "63183          1.0       2.0  ...       3.0      2.0      11.0       3.0   \n",
       "332946         2.0       2.0  ...       4.0      2.0      11.0       2.0   \n",
       "9756           3.0       2.0  ...      30.0      3.0      11.0       3.0   \n",
       "240811         7.0       2.0  ...       6.0      3.0       9.0       2.0   \n",
       "365554         4.0       2.0  ...       3.0      3.0       7.0       1.0   \n",
       "446372         2.0       2.0  ...      88.0      1.0      10.0       3.0   \n",
       "377079         3.0       2.0  ...       6.0      2.0       7.0       4.0   \n",
       "\n",
       "          CHECKUP1  INCOME2  _EDUCAG  SLEPTIM1  MENTHLTH  _SMOKER3  \n",
       "PERSONID                                                            \n",
       "355467         3.0      3.0      3.0       6.0      88.0       4.0  \n",
       "117235         1.0      4.0      2.0       7.0      88.0       4.0  \n",
       "268614         1.0      3.0      2.0       8.0       2.0       4.0  \n",
       "332821         1.0      8.0      4.0       6.0      15.0       3.0  \n",
       "348522         2.0      8.0      3.0       7.0      88.0       4.0  \n",
       "369924         1.0      3.0      3.0       6.0      88.0       4.0  \n",
       "229177         2.0      8.0      4.0       8.0      88.0       3.0  \n",
       "264514         1.0      8.0      2.0       7.0      15.0       1.0  \n",
       "98374          1.0     99.0      4.0       8.0      88.0       4.0  \n",
       "112601         1.0      4.0      2.0       7.0      88.0       4.0  \n",
       "334663         1.0      7.0      4.0       8.0      88.0       3.0  \n",
       "464529         3.0      2.0      3.0       5.0      88.0       1.0  \n",
       "296926         1.0      8.0      4.0       7.0       3.0       4.0  \n",
       "63183          1.0      8.0      4.0       5.0      30.0       3.0  \n",
       "332946         1.0      7.0      4.0       7.0      88.0       3.0  \n",
       "9756           1.0      6.0      2.0       7.0      24.0       4.0  \n",
       "240811         2.0      8.0      2.0       9.0      88.0       3.0  \n",
       "365554         1.0      4.0      2.0      77.0      88.0       3.0  \n",
       "446372         3.0      7.0      4.0       8.0      88.0       3.0  \n",
       "377079         1.0      3.0      2.0       8.0      30.0       2.0  \n",
       "\n",
       "[20 rows x 33 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_dn = dc.merge(dn, how=\"inner\")\n",
    "alldf = dc_dn.merge(do, how=\"inner\")\n",
    "alldf.set_index(\"PERSONID\", inplace=True) # set the 'PERSONID' variable as Index key\n",
    "alldf.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of data without Categorical types to use for correlation\n",
    "alldf_tmp = alldf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = list(dc.columns[1:])\n",
    "cat_columns.extend(\n",
    "    [\"GENHLTH\", \"_AGEG5YR\", \"_BMI5CAT\", \"CHECKUP1\", \"INCOME2\", \"_EDUCAG\", \"_SMOKER3\"]\n",
    ")\n",
    "\n",
    "'''\n",
    "not very necessary as floating point could also represent categories and then we could use\n",
    "columns.value_counts() to get the statistical summary.\n",
    "'''\n",
    "\n",
    "'''\n",
    "for c in cat_columns:\n",
    "    alldf[c] = pd.Categorical(alldf[c]) \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c. Describe the dataset and its basic characteristics (e.g., shape, variable types, basic stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alldf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8372/1077584923.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0malldf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'alldf' is not defined"
     ]
    }
   ],
   "source": [
    "alldf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIABETE3</th>\n",
       "      <th>_RACE</th>\n",
       "      <th>MSCODE</th>\n",
       "      <th>FLUSHOT6</th>\n",
       "      <th>EMPLOY1</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>CVDCRHD4</th>\n",
       "      <th>HLTHCVR1</th>\n",
       "      <th>CHCKIDNY</th>\n",
       "      <th>...</th>\n",
       "      <th>DRVISITS</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>INCOME2</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>SLEPTIM1</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>_SMOKER3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.0000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.764200</td>\n",
       "      <td>1.981800</td>\n",
       "      <td>2.915600</td>\n",
       "      <td>1.590400</td>\n",
       "      <td>3.921000</td>\n",
       "      <td>1.589200</td>\n",
       "      <td>2.226800</td>\n",
       "      <td>1.984800</td>\n",
       "      <td>3.259200</td>\n",
       "      <td>1.990800</td>\n",
       "      <td>...</td>\n",
       "      <td>12.617600</td>\n",
       "      <td>2.558400</td>\n",
       "      <td>7.8418</td>\n",
       "      <td>2.937000</td>\n",
       "      <td>1.588400</td>\n",
       "      <td>17.854400</td>\n",
       "      <td>2.988200</td>\n",
       "      <td>7.942400</td>\n",
       "      <td>65.437000</td>\n",
       "      <td>3.556200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.715193</td>\n",
       "      <td>2.241088</td>\n",
       "      <td>1.349385</td>\n",
       "      <td>0.713814</td>\n",
       "      <td>2.851453</td>\n",
       "      <td>0.492028</td>\n",
       "      <td>1.658406</td>\n",
       "      <td>0.571519</td>\n",
       "      <td>9.680246</td>\n",
       "      <td>0.435377</td>\n",
       "      <td>...</td>\n",
       "      <td>24.200176</td>\n",
       "      <td>1.108348</td>\n",
       "      <td>3.4858</td>\n",
       "      <td>0.808432</td>\n",
       "      <td>1.256225</td>\n",
       "      <td>29.824505</td>\n",
       "      <td>1.127437</td>\n",
       "      <td>8.228574</td>\n",
       "      <td>35.469943</td>\n",
       "      <td>1.513043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DIABETE3        _RACE       MSCODE     FLUSHOT6      EMPLOY1  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean      2.764200     1.981800     2.915600     1.590400     3.921000   \n",
       "std       0.715193     2.241088     1.349385     0.713814     2.851453   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%       3.000000     1.000000     2.000000     1.000000     1.000000   \n",
       "50%       3.000000     1.000000     3.000000     2.000000     3.000000   \n",
       "75%       3.000000     1.000000     3.000000     2.000000     7.000000   \n",
       "max       9.000000     9.000000     5.000000     9.000000     9.000000   \n",
       "\n",
       "               SEX      MARITAL     CVDCRHD4     HLTHCVR1     CHCKIDNY  ...  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000  ...   \n",
       "mean      1.589200     2.226800     1.984800     3.259200     1.990800  ...   \n",
       "std       0.492028     1.658406     0.571519     9.680246     0.435377  ...   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "25%       1.000000     1.000000     2.000000     1.000000     2.000000  ...   \n",
       "50%       2.000000     1.000000     2.000000     2.000000     2.000000  ...   \n",
       "75%       2.000000     3.000000     2.000000     3.000000     2.000000  ...   \n",
       "max       2.000000     9.000000     9.000000    99.000000     9.000000  ...   \n",
       "\n",
       "          DRVISITS      GENHLTH   _AGEG5YR     _BMI5CAT     CHECKUP1  \\\n",
       "count  5000.000000  5000.000000  5000.0000  5000.000000  5000.000000   \n",
       "mean     12.617600     2.558400     7.8418     2.937000     1.588400   \n",
       "std      24.200176     1.108348     3.4858     0.808432     1.256225   \n",
       "min       1.000000     1.000000     1.0000     1.000000     1.000000   \n",
       "25%       3.000000     2.000000     5.0000     2.000000     1.000000   \n",
       "50%       4.000000     2.000000     8.0000     3.000000     1.000000   \n",
       "75%       6.000000     3.000000    10.0000     4.000000     2.000000   \n",
       "max      99.000000     9.000000    14.0000     4.000000     9.000000   \n",
       "\n",
       "           INCOME2      _EDUCAG     SLEPTIM1     MENTHLTH     _SMOKER3  \n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000  \n",
       "mean     17.854400     2.988200     7.942400    65.437000     3.556200  \n",
       "std      29.824505     1.127437     8.228574    35.469943     1.513043  \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "25%       5.000000     2.000000     6.000000    30.000000     3.000000  \n",
       "50%       7.000000     3.000000     7.000000    88.000000     4.000000  \n",
       "75%       8.000000     4.000000     8.000000    88.000000     4.000000  \n",
       "max      99.000000     9.000000    99.000000    99.000000     9.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Drop NA/missing/refused/do not know/not sure values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing(df, print_col=None):\n",
    "    \"\"\"\n",
    "    drop BLANK/missing/refused/don't know/not sure values - inferred from the variable dictionary - from each column\n",
    "    \"\"\"\n",
    "    drop_vals = {\n",
    "        # \"PERSONID\": [],\n",
    "        #\"DIABETE3\": [7, 9],\n",
    "        \"_RACE\": [9],\n",
    "        # \"MSCODE\": [],\n",
    "        \"EMPLOY1\": [9],\n",
    "        # \"SEX\": [],\n",
    "        \"MARITAL\": [9],\n",
    "        \"RENTHOM1\": [7, 9],\n",
    "        # \"_STATE\": [],\n",
    "        # \"NUMADULT\": [],\n",
    "        \"CHILDREN\": [99],\n",
    "        \"INCOME2\": [77, 99],\n",
    "        \"_EDUCAG\": [9],\n",
    "        \"WEIGHT2\": [7777, 9999],\n",
    "        \"FLUSHOT6\": [7, 9],\n",
    "        \"CVDCRHD4\": [7, 9],\n",
    "        \"HLTHCVR1\": [77, 99],\n",
    "        \"CHCKIDNY\": [7, 9],\n",
    "        \"USEEQUIP\": [7, 9],\n",
    "        \"_TOTINDA\": [9],\n",
    "        \"ADDEPEV2\": [7, 9],\n",
    "        \"EXERANY2\": [7, 9],\n",
    "        \"BLIND\": [7, 9],\n",
    "        \"DECIDE\": [7, 9],\n",
    "        \"HLTHPLN1\": [7, 9],\n",
    "        \"ASTHMA3\": [7, 9],\n",
    "        \"DRVISITS\": [77],\n",
    "        \"GENHLTH\": [7, 9],\n",
    "        \"_AGEG5YR\": [14],\n",
    "        # \"_BMI5CAT\": [],\n",
    "        \"CHECKUP1\": [7, 9],\n",
    "        \"SLEPTIM1\": [77, 99],\n",
    "        \"MENTHLTH\": [77, 99],\n",
    "        \"_SMOKER3\": [9],\n",
    "    }\n",
    "\n",
    "    for col, v in drop_vals.items():\n",
    "        df = df[~df[col].isin(v)]\n",
    "        if print_col:\n",
    "            print(\n",
    "                f\"\\n\\ncol = {col}-------\\ndf[{print_col}].value_counts():\\n{df[print_col].value_counts()}\"\n",
    "            )\n",
    "\n",
    "   #  df.dropna(inplace=True)  NAs has already been handled by replacement with median of each column.\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** HLTHPLN1 becomes NaN in corr() because I'm dropping rows with \"missing\"/\"refused\"/\"do not know\" values. Perhaps there's a better way to address these types of values than just deleting the full row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alldf_tmp = drop_missing(alldf_tmp, print_col=\"HLTHPLN1\")\n",
    "\n",
    "alldf = drop_missing(alldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Make WEIGHT2 as one metric\n",
    "   1. Arbitrarily chose pounds\n",
    "   2. 1 kg = 2.2 lbs\n",
    "   3. 9000 - 9998 is kg without first 9. Ex: 9139 = 139kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "alldf_.loc[alldf_tmp[\"WEIGHT2\"] > 999, \"WEIGHT2\"] -= 9000 #get kg\n",
    "alldf_tmp.loc[alldf_tmp[\"WEIGHT2\"] > 999, \"WEIGHT2\"] /= 2.2 #kg -> lbs\n",
    "\n",
    "'''\n",
    "alldf.loc[alldf[\"WEIGHT2\"] > 999, \"WEIGHT2\"] -= 9000 #get kg\n",
    "alldf.loc[alldf[\"WEIGHT2\"] > 999, \"WEIGHT2\"] /= 2.2 #kg -> lbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reduce DIABETE3 to 0 = negative diagnosis 1 = positive diagnosis as nuances don't matter, only whether someone has a positive/negative diagnosis\n",
    "   1. 1 and 2 = Yes, 3 and 4 = No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DIABETE3\n",
      "0            0\n",
      "1            0\n",
      "2            0\n",
      "3            0\n",
      "4            0\n",
      "...        ...\n",
      "3643         0\n",
      "3644         0\n",
      "3645         0\n",
      "3646         0\n",
      "3647         0\n",
      "\n",
      "[3648 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# very good modification of responses\n",
    "\n",
    "#alldf[\"DIABETE3\"] = np.where(alldf[\"DIABETE3\"] < 3, 1,0)\n",
    "alldf[\"DIABETE3\"] = np.where(alldf[\"DIABETE3\"] >=3, 0,1)\n",
    "print(alldf[['DIABETE3']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Turn MENTHLTH, DRVISITS, CHILDREN value 88 to 0\n",
    "   1. 88 means \"None\" for these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"MENTHLTH\", \"DRVISITS\", \"CHILDREN\"]:\n",
    "    alldf[col].replace({88: 0}, inplace=True) # this is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3185\n",
       "1     463\n",
       "Name: DIABETE3, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldf[\"DIABETE3\"].value_counts() # shows 3648 where initially told they have diabete3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new dataset shape, variable types, and basic stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alldf_new = alldf.copy()\n",
    "\n",
    "for c in cat_columns:\n",
    "    alldf_new[c] = pd.Categorical(alldf_new[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3648, 33)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldf_new= alldf.copy()\n",
    "alldf_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf_new.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIABETE3</th>\n",
       "      <th>_RACE</th>\n",
       "      <th>MSCODE</th>\n",
       "      <th>FLUSHOT6</th>\n",
       "      <th>EMPLOY1</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>CVDCRHD4</th>\n",
       "      <th>HLTHCVR1</th>\n",
       "      <th>CHCKIDNY</th>\n",
       "      <th>...</th>\n",
       "      <th>DRVISITS</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>INCOME2</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>SLEPTIM1</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>_SMOKER3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DIABETE3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041284</td>\n",
       "      <td>-0.001136</td>\n",
       "      <td>-0.065834</td>\n",
       "      <td>0.206484</td>\n",
       "      <td>-0.002651</td>\n",
       "      <td>-0.003851</td>\n",
       "      <td>-0.177345</td>\n",
       "      <td>0.097869</td>\n",
       "      <td>-0.140910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087882</td>\n",
       "      <td>0.271065</td>\n",
       "      <td>0.203310</td>\n",
       "      <td>0.192126</td>\n",
       "      <td>-0.116959</td>\n",
       "      <td>-0.109187</td>\n",
       "      <td>-0.076139</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>0.038853</td>\n",
       "      <td>0.000575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_RACE</th>\n",
       "      <td>0.041284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.041338</td>\n",
       "      <td>0.099391</td>\n",
       "      <td>-0.032729</td>\n",
       "      <td>0.030366</td>\n",
       "      <td>0.145637</td>\n",
       "      <td>0.015390</td>\n",
       "      <td>0.078145</td>\n",
       "      <td>-0.011761</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034167</td>\n",
       "      <td>0.108403</td>\n",
       "      <td>-0.178911</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.055437</td>\n",
       "      <td>-0.221331</td>\n",
       "      <td>-0.170091</td>\n",
       "      <td>-0.067171</td>\n",
       "      <td>0.087816</td>\n",
       "      <td>0.003762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSCODE</th>\n",
       "      <td>-0.001136</td>\n",
       "      <td>-0.041338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065510</td>\n",
       "      <td>-0.015193</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>-0.036725</td>\n",
       "      <td>0.012930</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048518</td>\n",
       "      <td>0.034150</td>\n",
       "      <td>-0.016645</td>\n",
       "      <td>0.040195</td>\n",
       "      <td>0.031890</td>\n",
       "      <td>-0.074533</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-0.000464</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>-0.025138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLUSHOT6</th>\n",
       "      <td>-0.065834</td>\n",
       "      <td>0.099391</td>\n",
       "      <td>0.065510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.135334</td>\n",
       "      <td>-0.055092</td>\n",
       "      <td>0.085690</td>\n",
       "      <td>0.052261</td>\n",
       "      <td>-0.028368</td>\n",
       "      <td>0.048428</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093990</td>\n",
       "      <td>-0.029441</td>\n",
       "      <td>-0.228402</td>\n",
       "      <td>-0.033960</td>\n",
       "      <td>0.196972</td>\n",
       "      <td>-0.080351</td>\n",
       "      <td>-0.091783</td>\n",
       "      <td>-0.064381</td>\n",
       "      <td>0.057271</td>\n",
       "      <td>-0.099866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMPLOY1</th>\n",
       "      <td>0.206484</td>\n",
       "      <td>-0.032729</td>\n",
       "      <td>-0.015193</td>\n",
       "      <td>-0.135334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.081342</td>\n",
       "      <td>-0.003280</td>\n",
       "      <td>-0.169819</td>\n",
       "      <td>0.352928</td>\n",
       "      <td>-0.138623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129699</td>\n",
       "      <td>0.309064</td>\n",
       "      <td>0.530909</td>\n",
       "      <td>0.046692</td>\n",
       "      <td>-0.142045</td>\n",
       "      <td>-0.336339</td>\n",
       "      <td>-0.183267</td>\n",
       "      <td>0.067158</td>\n",
       "      <td>0.081692</td>\n",
       "      <td>-0.048701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX</th>\n",
       "      <td>-0.002651</td>\n",
       "      <td>0.030366</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>-0.055092</td>\n",
       "      <td>0.081342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021061</td>\n",
       "      <td>0.037592</td>\n",
       "      <td>0.029234</td>\n",
       "      <td>0.008114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>-0.108211</td>\n",
       "      <td>-0.078651</td>\n",
       "      <td>-0.127647</td>\n",
       "      <td>-0.037182</td>\n",
       "      <td>0.015041</td>\n",
       "      <td>0.072185</td>\n",
       "      <td>0.049968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARITAL</th>\n",
       "      <td>-0.003851</td>\n",
       "      <td>0.145637</td>\n",
       "      <td>-0.036725</td>\n",
       "      <td>0.085690</td>\n",
       "      <td>-0.003280</td>\n",
       "      <td>0.021061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.112215</td>\n",
       "      <td>-0.007356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>0.063301</td>\n",
       "      <td>-0.208850</td>\n",
       "      <td>-0.033955</td>\n",
       "      <td>0.095521</td>\n",
       "      <td>-0.327489</td>\n",
       "      <td>-0.109703</td>\n",
       "      <td>-0.062603</td>\n",
       "      <td>0.088383</td>\n",
       "      <td>-0.069436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVDCRHD4</th>\n",
       "      <td>-0.177345</td>\n",
       "      <td>0.015390</td>\n",
       "      <td>0.012930</td>\n",
       "      <td>0.052261</td>\n",
       "      <td>-0.169819</td>\n",
       "      <td>0.037592</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.073971</td>\n",
       "      <td>0.108548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076097</td>\n",
       "      <td>-0.220392</td>\n",
       "      <td>-0.187457</td>\n",
       "      <td>-0.051788</td>\n",
       "      <td>0.064173</td>\n",
       "      <td>0.081282</td>\n",
       "      <td>0.054242</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>-0.049552</td>\n",
       "      <td>0.026675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HLTHCVR1</th>\n",
       "      <td>0.097869</td>\n",
       "      <td>0.078145</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>-0.028368</td>\n",
       "      <td>0.352928</td>\n",
       "      <td>0.029234</td>\n",
       "      <td>0.112215</td>\n",
       "      <td>-0.073971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.072270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084818</td>\n",
       "      <td>0.199136</td>\n",
       "      <td>0.218351</td>\n",
       "      <td>0.023432</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>-0.323532</td>\n",
       "      <td>-0.161679</td>\n",
       "      <td>0.016614</td>\n",
       "      <td>0.094933</td>\n",
       "      <td>-0.075218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHCKIDNY</th>\n",
       "      <td>-0.140910</td>\n",
       "      <td>-0.011761</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.048428</td>\n",
       "      <td>-0.138623</td>\n",
       "      <td>0.008114</td>\n",
       "      <td>-0.007356</td>\n",
       "      <td>0.108548</td>\n",
       "      <td>-0.072270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074173</td>\n",
       "      <td>-0.192510</td>\n",
       "      <td>-0.087681</td>\n",
       "      <td>-0.063476</td>\n",
       "      <td>0.021517</td>\n",
       "      <td>0.088566</td>\n",
       "      <td>0.024201</td>\n",
       "      <td>0.024203</td>\n",
       "      <td>-0.063168</td>\n",
       "      <td>0.017997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USEEQUIP</th>\n",
       "      <td>-0.157250</td>\n",
       "      <td>-0.001156</td>\n",
       "      <td>0.033722</td>\n",
       "      <td>0.092910</td>\n",
       "      <td>-0.280512</td>\n",
       "      <td>-0.021969</td>\n",
       "      <td>-0.056899</td>\n",
       "      <td>0.153462</td>\n",
       "      <td>-0.154250</td>\n",
       "      <td>0.150039</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168503</td>\n",
       "      <td>-0.343085</td>\n",
       "      <td>-0.213831</td>\n",
       "      <td>-0.103371</td>\n",
       "      <td>0.075475</td>\n",
       "      <td>0.225488</td>\n",
       "      <td>0.097106</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>-0.117525</td>\n",
       "      <td>0.035176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_TOTINDA</th>\n",
       "      <td>0.117916</td>\n",
       "      <td>0.058682</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.017725</td>\n",
       "      <td>0.151383</td>\n",
       "      <td>0.058770</td>\n",
       "      <td>0.047647</td>\n",
       "      <td>-0.093570</td>\n",
       "      <td>0.118612</td>\n",
       "      <td>-0.061463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058973</td>\n",
       "      <td>0.288158</td>\n",
       "      <td>0.110108</td>\n",
       "      <td>0.116587</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>-0.250821</td>\n",
       "      <td>-0.207789</td>\n",
       "      <td>-0.009473</td>\n",
       "      <td>0.131484</td>\n",
       "      <td>-0.109418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADDEPEV2</th>\n",
       "      <td>-0.114444</td>\n",
       "      <td>-0.021821</td>\n",
       "      <td>-0.003348</td>\n",
       "      <td>0.025823</td>\n",
       "      <td>-0.141966</td>\n",
       "      <td>-0.139380</td>\n",
       "      <td>-0.056011</td>\n",
       "      <td>0.080653</td>\n",
       "      <td>-0.101789</td>\n",
       "      <td>0.105979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159595</td>\n",
       "      <td>-0.272978</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>-0.076276</td>\n",
       "      <td>0.008445</td>\n",
       "      <td>0.209108</td>\n",
       "      <td>0.074713</td>\n",
       "      <td>0.087511</td>\n",
       "      <td>-0.411461</td>\n",
       "      <td>0.154992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RENTHOM1</th>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.176905</td>\n",
       "      <td>-0.012682</td>\n",
       "      <td>0.112390</td>\n",
       "      <td>-0.011638</td>\n",
       "      <td>0.019288</td>\n",
       "      <td>0.303720</td>\n",
       "      <td>0.006644</td>\n",
       "      <td>0.097147</td>\n",
       "      <td>-0.030807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034733</td>\n",
       "      <td>0.108260</td>\n",
       "      <td>-0.265009</td>\n",
       "      <td>0.037203</td>\n",
       "      <td>0.105672</td>\n",
       "      <td>-0.357230</td>\n",
       "      <td>-0.148781</td>\n",
       "      <td>-0.019415</td>\n",
       "      <td>0.134405</td>\n",
       "      <td>-0.091735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXERANY2</th>\n",
       "      <td>0.117916</td>\n",
       "      <td>0.058682</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.017725</td>\n",
       "      <td>0.151383</td>\n",
       "      <td>0.058770</td>\n",
       "      <td>0.047647</td>\n",
       "      <td>-0.093570</td>\n",
       "      <td>0.118612</td>\n",
       "      <td>-0.061463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058973</td>\n",
       "      <td>0.288158</td>\n",
       "      <td>0.110108</td>\n",
       "      <td>0.116587</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>-0.250821</td>\n",
       "      <td>-0.207789</td>\n",
       "      <td>-0.009473</td>\n",
       "      <td>0.131484</td>\n",
       "      <td>-0.109418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLIND</th>\n",
       "      <td>-0.077310</td>\n",
       "      <td>-0.045975</td>\n",
       "      <td>-0.034012</td>\n",
       "      <td>-0.023756</td>\n",
       "      <td>-0.138194</td>\n",
       "      <td>-0.009812</td>\n",
       "      <td>-0.037449</td>\n",
       "      <td>0.098160</td>\n",
       "      <td>-0.087705</td>\n",
       "      <td>0.068852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078630</td>\n",
       "      <td>-0.163002</td>\n",
       "      <td>-0.032357</td>\n",
       "      <td>-0.020265</td>\n",
       "      <td>-0.008179</td>\n",
       "      <td>0.214610</td>\n",
       "      <td>0.130545</td>\n",
       "      <td>0.050409</td>\n",
       "      <td>-0.141854</td>\n",
       "      <td>0.092733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DECIDE</th>\n",
       "      <td>-0.091564</td>\n",
       "      <td>-0.064620</td>\n",
       "      <td>-0.010809</td>\n",
       "      <td>-0.013377</td>\n",
       "      <td>-0.187783</td>\n",
       "      <td>-0.035853</td>\n",
       "      <td>-0.089876</td>\n",
       "      <td>0.087091</td>\n",
       "      <td>-0.144995</td>\n",
       "      <td>0.106291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146974</td>\n",
       "      <td>-0.297414</td>\n",
       "      <td>-0.002436</td>\n",
       "      <td>-0.080251</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.280871</td>\n",
       "      <td>0.142564</td>\n",
       "      <td>0.107372</td>\n",
       "      <td>-0.410639</td>\n",
       "      <td>0.150784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HLTHPLN1</th>\n",
       "      <td>-0.050576</td>\n",
       "      <td>0.129416</td>\n",
       "      <td>0.032475</td>\n",
       "      <td>0.160530</td>\n",
       "      <td>-0.113429</td>\n",
       "      <td>-0.017971</td>\n",
       "      <td>0.152109</td>\n",
       "      <td>0.036841</td>\n",
       "      <td>-0.020073</td>\n",
       "      <td>0.039155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074042</td>\n",
       "      <td>0.026669</td>\n",
       "      <td>-0.197502</td>\n",
       "      <td>-0.039247</td>\n",
       "      <td>0.223461</td>\n",
       "      <td>-0.210756</td>\n",
       "      <td>-0.132950</td>\n",
       "      <td>-0.076248</td>\n",
       "      <td>0.054327</td>\n",
       "      <td>-0.111724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_STATE</th>\n",
       "      <td>-0.009980</td>\n",
       "      <td>0.079769</td>\n",
       "      <td>0.101561</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>-0.026647</td>\n",
       "      <td>0.037066</td>\n",
       "      <td>-0.007963</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>-0.016562</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016417</td>\n",
       "      <td>0.012087</td>\n",
       "      <td>-0.030107</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>-0.048015</td>\n",
       "      <td>-0.039426</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>-0.005382</td>\n",
       "      <td>-0.012932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASTHMA3</th>\n",
       "      <td>-0.007013</td>\n",
       "      <td>-0.013252</td>\n",
       "      <td>0.024671</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>-0.031870</td>\n",
       "      <td>-0.056644</td>\n",
       "      <td>-0.047677</td>\n",
       "      <td>0.063502</td>\n",
       "      <td>-0.028261</td>\n",
       "      <td>0.064770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088653</td>\n",
       "      <td>-0.121731</td>\n",
       "      <td>0.076665</td>\n",
       "      <td>-0.058965</td>\n",
       "      <td>0.031953</td>\n",
       "      <td>0.078743</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.049632</td>\n",
       "      <td>-0.138434</td>\n",
       "      <td>0.030739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUMADULT</th>\n",
       "      <td>-0.058425</td>\n",
       "      <td>0.092385</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.065308</td>\n",
       "      <td>-0.188665</td>\n",
       "      <td>-0.045488</td>\n",
       "      <td>-0.210480</td>\n",
       "      <td>0.071843</td>\n",
       "      <td>-0.088329</td>\n",
       "      <td>0.014748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057430</td>\n",
       "      <td>-0.107463</td>\n",
       "      <td>-0.260044</td>\n",
       "      <td>-0.008981</td>\n",
       "      <td>0.050178</td>\n",
       "      <td>0.162890</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>-0.010933</td>\n",
       "      <td>0.016437</td>\n",
       "      <td>0.026347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHILDREN</th>\n",
       "      <td>-0.113900</td>\n",
       "      <td>0.123902</td>\n",
       "      <td>-0.014243</td>\n",
       "      <td>0.090392</td>\n",
       "      <td>-0.221033</td>\n",
       "      <td>0.031079</td>\n",
       "      <td>-0.094099</td>\n",
       "      <td>0.091353</td>\n",
       "      <td>-0.105553</td>\n",
       "      <td>0.034171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004009</td>\n",
       "      <td>-0.088744</td>\n",
       "      <td>-0.443593</td>\n",
       "      <td>-0.003018</td>\n",
       "      <td>0.088896</td>\n",
       "      <td>0.072390</td>\n",
       "      <td>0.031010</td>\n",
       "      <td>-0.074253</td>\n",
       "      <td>0.069551</td>\n",
       "      <td>0.019666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEIGHT2</th>\n",
       "      <td>0.158867</td>\n",
       "      <td>-0.033995</td>\n",
       "      <td>0.025870</td>\n",
       "      <td>-0.003181</td>\n",
       "      <td>-0.036014</td>\n",
       "      <td>-0.402974</td>\n",
       "      <td>-0.015512</td>\n",
       "      <td>-0.053547</td>\n",
       "      <td>-0.029717</td>\n",
       "      <td>-0.063590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023106</td>\n",
       "      <td>0.186750</td>\n",
       "      <td>-0.055474</td>\n",
       "      <td>0.744654</td>\n",
       "      <td>-0.017909</td>\n",
       "      <td>0.040037</td>\n",
       "      <td>-0.014641</td>\n",
       "      <td>-0.047362</td>\n",
       "      <td>0.058199</td>\n",
       "      <td>-0.008605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRVISITS</th>\n",
       "      <td>0.087882</td>\n",
       "      <td>-0.034167</td>\n",
       "      <td>-0.048518</td>\n",
       "      <td>-0.093990</td>\n",
       "      <td>0.129699</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>-0.076097</td>\n",
       "      <td>0.084818</td>\n",
       "      <td>-0.074173</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.212312</td>\n",
       "      <td>0.039367</td>\n",
       "      <td>0.060878</td>\n",
       "      <td>-0.084104</td>\n",
       "      <td>-0.027830</td>\n",
       "      <td>0.053676</td>\n",
       "      <td>-0.024291</td>\n",
       "      <td>0.138997</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GENHLTH</th>\n",
       "      <td>0.271065</td>\n",
       "      <td>0.108403</td>\n",
       "      <td>0.034150</td>\n",
       "      <td>-0.029441</td>\n",
       "      <td>0.309064</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.063301</td>\n",
       "      <td>-0.220392</td>\n",
       "      <td>0.199136</td>\n",
       "      <td>-0.192510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212312</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169019</td>\n",
       "      <td>0.238482</td>\n",
       "      <td>-0.060603</td>\n",
       "      <td>-0.354000</td>\n",
       "      <td>-0.266720</td>\n",
       "      <td>-0.101315</td>\n",
       "      <td>0.276350</td>\n",
       "      <td>-0.193193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <td>0.203310</td>\n",
       "      <td>-0.178911</td>\n",
       "      <td>-0.016645</td>\n",
       "      <td>-0.228402</td>\n",
       "      <td>0.530909</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>-0.208850</td>\n",
       "      <td>-0.187457</td>\n",
       "      <td>0.218351</td>\n",
       "      <td>-0.087681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039367</td>\n",
       "      <td>0.169019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030915</td>\n",
       "      <td>-0.198999</td>\n",
       "      <td>-0.080954</td>\n",
       "      <td>-0.049105</td>\n",
       "      <td>0.106209</td>\n",
       "      <td>-0.118018</td>\n",
       "      <td>0.019265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <td>0.192126</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.040195</td>\n",
       "      <td>-0.033960</td>\n",
       "      <td>0.046692</td>\n",
       "      <td>-0.108211</td>\n",
       "      <td>-0.033955</td>\n",
       "      <td>-0.051788</td>\n",
       "      <td>0.023432</td>\n",
       "      <td>-0.063476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060878</td>\n",
       "      <td>0.238482</td>\n",
       "      <td>0.030915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.075140</td>\n",
       "      <td>-0.043052</td>\n",
       "      <td>-0.092118</td>\n",
       "      <td>-0.032121</td>\n",
       "      <td>0.075634</td>\n",
       "      <td>0.001757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHECKUP1</th>\n",
       "      <td>-0.116959</td>\n",
       "      <td>0.055437</td>\n",
       "      <td>0.031890</td>\n",
       "      <td>0.196972</td>\n",
       "      <td>-0.142045</td>\n",
       "      <td>-0.078651</td>\n",
       "      <td>0.095521</td>\n",
       "      <td>0.064173</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0.021517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084104</td>\n",
       "      <td>-0.060603</td>\n",
       "      <td>-0.198999</td>\n",
       "      <td>-0.075140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.065527</td>\n",
       "      <td>-0.046800</td>\n",
       "      <td>-0.045168</td>\n",
       "      <td>0.032811</td>\n",
       "      <td>-0.070213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INCOME2</th>\n",
       "      <td>-0.109187</td>\n",
       "      <td>-0.221331</td>\n",
       "      <td>-0.074533</td>\n",
       "      <td>-0.080351</td>\n",
       "      <td>-0.336339</td>\n",
       "      <td>-0.127647</td>\n",
       "      <td>-0.327489</td>\n",
       "      <td>0.081282</td>\n",
       "      <td>-0.323532</td>\n",
       "      <td>0.088566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027830</td>\n",
       "      <td>-0.354000</td>\n",
       "      <td>-0.080954</td>\n",
       "      <td>-0.043052</td>\n",
       "      <td>-0.065527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.456141</td>\n",
       "      <td>0.055410</td>\n",
       "      <td>-0.220754</td>\n",
       "      <td>0.214167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_EDUCAG</th>\n",
       "      <td>-0.076139</td>\n",
       "      <td>-0.170091</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-0.091783</td>\n",
       "      <td>-0.183267</td>\n",
       "      <td>-0.037182</td>\n",
       "      <td>-0.109703</td>\n",
       "      <td>0.054242</td>\n",
       "      <td>-0.161679</td>\n",
       "      <td>0.024201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053676</td>\n",
       "      <td>-0.266720</td>\n",
       "      <td>-0.049105</td>\n",
       "      <td>-0.092118</td>\n",
       "      <td>-0.046800</td>\n",
       "      <td>0.456141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>-0.126862</td>\n",
       "      <td>0.239848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLEPTIM1</th>\n",
       "      <td>0.005108</td>\n",
       "      <td>-0.067171</td>\n",
       "      <td>-0.000464</td>\n",
       "      <td>-0.064381</td>\n",
       "      <td>0.067158</td>\n",
       "      <td>0.015041</td>\n",
       "      <td>-0.062603</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.016614</td>\n",
       "      <td>0.024203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024291</td>\n",
       "      <td>-0.101315</td>\n",
       "      <td>0.106209</td>\n",
       "      <td>-0.032121</td>\n",
       "      <td>-0.045168</td>\n",
       "      <td>0.055410</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.172066</td>\n",
       "      <td>0.088734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MENTHLTH</th>\n",
       "      <td>0.038853</td>\n",
       "      <td>0.087816</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>0.057271</td>\n",
       "      <td>0.081692</td>\n",
       "      <td>0.072185</td>\n",
       "      <td>0.088383</td>\n",
       "      <td>-0.049552</td>\n",
       "      <td>0.094933</td>\n",
       "      <td>-0.063168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138997</td>\n",
       "      <td>0.276350</td>\n",
       "      <td>-0.118018</td>\n",
       "      <td>0.075634</td>\n",
       "      <td>0.032811</td>\n",
       "      <td>-0.220754</td>\n",
       "      <td>-0.126862</td>\n",
       "      <td>-0.172066</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.166543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_SMOKER3</th>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>-0.025138</td>\n",
       "      <td>-0.099866</td>\n",
       "      <td>-0.048701</td>\n",
       "      <td>0.049968</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>0.026675</td>\n",
       "      <td>-0.075218</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>-0.193193</td>\n",
       "      <td>0.019265</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>-0.070213</td>\n",
       "      <td>0.214167</td>\n",
       "      <td>0.239848</td>\n",
       "      <td>0.088734</td>\n",
       "      <td>-0.166543</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DIABETE3     _RACE    MSCODE  FLUSHOT6   EMPLOY1       SEX  \\\n",
       "DIABETE3  1.000000  0.041284 -0.001136 -0.065834  0.206484 -0.002651   \n",
       "_RACE     0.041284  1.000000 -0.041338  0.099391 -0.032729  0.030366   \n",
       "MSCODE   -0.001136 -0.041338  1.000000  0.065510 -0.015193  0.012462   \n",
       "FLUSHOT6 -0.065834  0.099391  0.065510  1.000000 -0.135334 -0.055092   \n",
       "EMPLOY1   0.206484 -0.032729 -0.015193 -0.135334  1.000000  0.081342   \n",
       "SEX      -0.002651  0.030366  0.012462 -0.055092  0.081342  1.000000   \n",
       "MARITAL  -0.003851  0.145637 -0.036725  0.085690 -0.003280  0.021061   \n",
       "CVDCRHD4 -0.177345  0.015390  0.012930  0.052261 -0.169819  0.037592   \n",
       "HLTHCVR1  0.097869  0.078145  0.009260 -0.028368  0.352928  0.029234   \n",
       "CHCKIDNY -0.140910 -0.011761  0.002076  0.048428 -0.138623  0.008114   \n",
       "USEEQUIP -0.157250 -0.001156  0.033722  0.092910 -0.280512 -0.021969   \n",
       "_TOTINDA  0.117916  0.058682  0.031600  0.017725  0.151383  0.058770   \n",
       "ADDEPEV2 -0.114444 -0.021821 -0.003348  0.025823 -0.141966 -0.139380   \n",
       "RENTHOM1  0.000103  0.176905 -0.012682  0.112390 -0.011638  0.019288   \n",
       "EXERANY2  0.117916  0.058682  0.031600  0.017725  0.151383  0.058770   \n",
       "BLIND    -0.077310 -0.045975 -0.034012 -0.023756 -0.138194 -0.009812   \n",
       "DECIDE   -0.091564 -0.064620 -0.010809 -0.013377 -0.187783 -0.035853   \n",
       "HLTHPLN1 -0.050576  0.129416  0.032475  0.160530 -0.113429 -0.017971   \n",
       "_STATE   -0.009980  0.079769  0.101561  0.000466 -0.026647  0.037066   \n",
       "ASTHMA3  -0.007013 -0.013252  0.024671  0.033766 -0.031870 -0.056644   \n",
       "NUMADULT -0.058425  0.092385  0.008175  0.065308 -0.188665 -0.045488   \n",
       "CHILDREN -0.113900  0.123902 -0.014243  0.090392 -0.221033  0.031079   \n",
       "WEIGHT2   0.158867 -0.033995  0.025870 -0.003181 -0.036014 -0.402974   \n",
       "DRVISITS  0.087882 -0.034167 -0.048518 -0.093990  0.129699  0.078600   \n",
       "GENHLTH   0.271065  0.108403  0.034150 -0.029441  0.309064  0.005983   \n",
       "_AGEG5YR  0.203310 -0.178911 -0.016645 -0.228402  0.530909  0.028168   \n",
       "_BMI5CAT  0.192126  0.027972  0.040195 -0.033960  0.046692 -0.108211   \n",
       "CHECKUP1 -0.116959  0.055437  0.031890  0.196972 -0.142045 -0.078651   \n",
       "INCOME2  -0.109187 -0.221331 -0.074533 -0.080351 -0.336339 -0.127647   \n",
       "_EDUCAG  -0.076139 -0.170091 -0.104191 -0.091783 -0.183267 -0.037182   \n",
       "SLEPTIM1  0.005108 -0.067171 -0.000464 -0.064381  0.067158  0.015041   \n",
       "MENTHLTH  0.038853  0.087816  0.010879  0.057271  0.081692  0.072185   \n",
       "_SMOKER3  0.000575  0.003762 -0.025138 -0.099866 -0.048701  0.049968   \n",
       "\n",
       "           MARITAL  CVDCRHD4  HLTHCVR1  CHCKIDNY  ...  DRVISITS   GENHLTH  \\\n",
       "DIABETE3 -0.003851 -0.177345  0.097869 -0.140910  ...  0.087882  0.271065   \n",
       "_RACE     0.145637  0.015390  0.078145 -0.011761  ... -0.034167  0.108403   \n",
       "MSCODE   -0.036725  0.012930  0.009260  0.002076  ... -0.048518  0.034150   \n",
       "FLUSHOT6  0.085690  0.052261 -0.028368  0.048428  ... -0.093990 -0.029441   \n",
       "EMPLOY1  -0.003280 -0.169819  0.352928 -0.138623  ...  0.129699  0.309064   \n",
       "SEX       0.021061  0.037592  0.029234  0.008114  ...  0.078600  0.005983   \n",
       "MARITAL   1.000000  0.008398  0.112215 -0.007356  ...  0.033715  0.063301   \n",
       "CVDCRHD4  0.008398  1.000000 -0.073971  0.108548  ... -0.076097 -0.220392   \n",
       "HLTHCVR1  0.112215 -0.073971  1.000000 -0.072270  ...  0.084818  0.199136   \n",
       "CHCKIDNY -0.007356  0.108548 -0.072270  1.000000  ... -0.074173 -0.192510   \n",
       "USEEQUIP -0.056899  0.153462 -0.154250  0.150039  ... -0.168503 -0.343085   \n",
       "_TOTINDA  0.047647 -0.093570  0.118612 -0.061463  ...  0.058973  0.288158   \n",
       "ADDEPEV2 -0.056011  0.080653 -0.101789  0.105979  ... -0.159595 -0.272978   \n",
       "RENTHOM1  0.303720  0.006644  0.097147 -0.030807  ...  0.034733  0.108260   \n",
       "EXERANY2  0.047647 -0.093570  0.118612 -0.061463  ...  0.058973  0.288158   \n",
       "BLIND    -0.037449  0.098160 -0.087705  0.068852  ... -0.078630 -0.163002   \n",
       "DECIDE   -0.089876  0.087091 -0.144995  0.106291  ... -0.146974 -0.297414   \n",
       "HLTHPLN1  0.152109  0.036841 -0.020073  0.039155  ... -0.074042  0.026669   \n",
       "_STATE   -0.007963  0.005801 -0.016562  0.004215  ... -0.016417  0.012087   \n",
       "ASTHMA3  -0.047677  0.063502 -0.028261  0.064770  ... -0.088653 -0.121731   \n",
       "NUMADULT -0.210480  0.071843 -0.088329  0.014748  ... -0.057430 -0.107463   \n",
       "CHILDREN -0.094099  0.091353 -0.105553  0.034171  ... -0.004009 -0.088744   \n",
       "WEIGHT2  -0.015512 -0.053547 -0.029717 -0.063590  ...  0.023106  0.186750   \n",
       "DRVISITS  0.033715 -0.076097  0.084818 -0.074173  ...  1.000000  0.212312   \n",
       "GENHLTH   0.063301 -0.220392  0.199136 -0.192510  ...  0.212312  1.000000   \n",
       "_AGEG5YR -0.208850 -0.187457  0.218351 -0.087681  ...  0.039367  0.169019   \n",
       "_BMI5CAT -0.033955 -0.051788  0.023432 -0.063476  ...  0.060878  0.238482   \n",
       "CHECKUP1  0.095521  0.064173 -0.031193  0.021517  ... -0.084104 -0.060603   \n",
       "INCOME2  -0.327489  0.081282 -0.323532  0.088566  ... -0.027830 -0.354000   \n",
       "_EDUCAG  -0.109703  0.054242 -0.161679  0.024201  ...  0.053676 -0.266720   \n",
       "SLEPTIM1 -0.062603  0.006100  0.016614  0.024203  ... -0.024291 -0.101315   \n",
       "MENTHLTH  0.088383 -0.049552  0.094933 -0.063168  ...  0.138997  0.276350   \n",
       "_SMOKER3 -0.069436  0.026675 -0.075218  0.017997  ...  0.000806 -0.193193   \n",
       "\n",
       "          _AGEG5YR  _BMI5CAT  CHECKUP1   INCOME2   _EDUCAG  SLEPTIM1  \\\n",
       "DIABETE3  0.203310  0.192126 -0.116959 -0.109187 -0.076139  0.005108   \n",
       "_RACE    -0.178911  0.027972  0.055437 -0.221331 -0.170091 -0.067171   \n",
       "MSCODE   -0.016645  0.040195  0.031890 -0.074533 -0.104191 -0.000464   \n",
       "FLUSHOT6 -0.228402 -0.033960  0.196972 -0.080351 -0.091783 -0.064381   \n",
       "EMPLOY1   0.530909  0.046692 -0.142045 -0.336339 -0.183267  0.067158   \n",
       "SEX       0.028168 -0.108211 -0.078651 -0.127647 -0.037182  0.015041   \n",
       "MARITAL  -0.208850 -0.033955  0.095521 -0.327489 -0.109703 -0.062603   \n",
       "CVDCRHD4 -0.187457 -0.051788  0.064173  0.081282  0.054242  0.006100   \n",
       "HLTHCVR1  0.218351  0.023432 -0.031193 -0.323532 -0.161679  0.016614   \n",
       "CHCKIDNY -0.087681 -0.063476  0.021517  0.088566  0.024201  0.024203   \n",
       "USEEQUIP -0.213831 -0.103371  0.075475  0.225488  0.097106  0.008293   \n",
       "_TOTINDA  0.110108  0.116587  0.000662 -0.250821 -0.207789 -0.009473   \n",
       "ADDEPEV2  0.001632 -0.076276  0.008445  0.209108  0.074713  0.087511   \n",
       "RENTHOM1 -0.265009  0.037203  0.105672 -0.357230 -0.148781 -0.019415   \n",
       "EXERANY2  0.110108  0.116587  0.000662 -0.250821 -0.207789 -0.009473   \n",
       "BLIND    -0.032357 -0.020265 -0.008179  0.214610  0.130545  0.050409   \n",
       "DECIDE   -0.002436 -0.080251  0.006570  0.280871  0.142564  0.107372   \n",
       "HLTHPLN1 -0.197502 -0.039247  0.223461 -0.210756 -0.132950 -0.076248   \n",
       "_STATE   -0.030107  0.010396  0.004736 -0.048015 -0.039426  0.009807   \n",
       "ASTHMA3   0.076665 -0.058965  0.031953  0.078743  0.007470  0.049632   \n",
       "NUMADULT -0.260044 -0.008981  0.050178  0.162890  0.003203 -0.010933   \n",
       "CHILDREN -0.443593 -0.003018  0.088896  0.072390  0.031010 -0.074253   \n",
       "WEIGHT2  -0.055474  0.744654 -0.017909  0.040037 -0.014641 -0.047362   \n",
       "DRVISITS  0.039367  0.060878 -0.084104 -0.027830  0.053676 -0.024291   \n",
       "GENHLTH   0.169019  0.238482 -0.060603 -0.354000 -0.266720 -0.101315   \n",
       "_AGEG5YR  1.000000  0.030915 -0.198999 -0.080954 -0.049105  0.106209   \n",
       "_BMI5CAT  0.030915  1.000000 -0.075140 -0.043052 -0.092118 -0.032121   \n",
       "CHECKUP1 -0.198999 -0.075140  1.000000 -0.065527 -0.046800 -0.045168   \n",
       "INCOME2  -0.080954 -0.043052 -0.065527  1.000000  0.456141  0.055410   \n",
       "_EDUCAG  -0.049105 -0.092118 -0.046800  0.456141  1.000000  0.024500   \n",
       "SLEPTIM1  0.106209 -0.032121 -0.045168  0.055410  0.024500  1.000000   \n",
       "MENTHLTH -0.118018  0.075634  0.032811 -0.220754 -0.126862 -0.172066   \n",
       "_SMOKER3  0.019265  0.001757 -0.070213  0.214167  0.239848  0.088734   \n",
       "\n",
       "          MENTHLTH  _SMOKER3  \n",
       "DIABETE3  0.038853  0.000575  \n",
       "_RACE     0.087816  0.003762  \n",
       "MSCODE    0.010879 -0.025138  \n",
       "FLUSHOT6  0.057271 -0.099866  \n",
       "EMPLOY1   0.081692 -0.048701  \n",
       "SEX       0.072185  0.049968  \n",
       "MARITAL   0.088383 -0.069436  \n",
       "CVDCRHD4 -0.049552  0.026675  \n",
       "HLTHCVR1  0.094933 -0.075218  \n",
       "CHCKIDNY -0.063168  0.017997  \n",
       "USEEQUIP -0.117525  0.035176  \n",
       "_TOTINDA  0.131484 -0.109418  \n",
       "ADDEPEV2 -0.411461  0.154992  \n",
       "RENTHOM1  0.134405 -0.091735  \n",
       "EXERANY2  0.131484 -0.109418  \n",
       "BLIND    -0.141854  0.092733  \n",
       "DECIDE   -0.410639  0.150784  \n",
       "HLTHPLN1  0.054327 -0.111724  \n",
       "_STATE   -0.005382 -0.012932  \n",
       "ASTHMA3  -0.138434  0.030739  \n",
       "NUMADULT  0.016437  0.026347  \n",
       "CHILDREN  0.069551  0.019666  \n",
       "WEIGHT2   0.058199 -0.008605  \n",
       "DRVISITS  0.138997  0.000806  \n",
       "GENHLTH   0.276350 -0.193193  \n",
       "_AGEG5YR -0.118018  0.019265  \n",
       "_BMI5CAT  0.075634  0.001757  \n",
       "CHECKUP1  0.032811 -0.070213  \n",
       "INCOME2  -0.220754  0.214167  \n",
       "_EDUCAG  -0.126862  0.239848  \n",
       "SLEPTIM1 -0.172066  0.088734  \n",
       "MENTHLTH  1.000000 -0.166543  \n",
       "_SMOKER3 -0.166543  1.000000  \n",
       "\n",
       "[33 rows x 33 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldf_new.corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # for heatmap\n",
    "plt.figure(figsize = (12, 8))\n",
    "\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap = True)\n",
    "\n",
    "sns.heatmap(alldf_new.corr(), annot =True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Distribution Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Choose several variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = alldf_new.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b Create visualizations to show their distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make target variable distribution\n",
    "\n",
    "ax =sns.countplot(x=\"DIABETE3\", data=alldf_new)\n",
    "plt.title(\"Diabetes Distribution\")\n",
    "ax.tick_params(axis='x', colors='red')  # Change x-axis label color to red\n",
    "ax.tick_params(axis='y', colors='red')  # Change y-axis label color to red\n",
    "\n",
    "\n",
    "# it's an imbalanced distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0     1149\n",
      "8.0     1055\n",
      "6.0      806\n",
      "5.0      231\n",
      "9.0      172\n",
      "4.0      101\n",
      "10.0      73\n",
      "12.0      23\n",
      "3.0       16\n",
      "2.0        8\n",
      "11.0       6\n",
      "13.0       2\n",
      "15.0       2\n",
      "18.0       1\n",
      "14.0       1\n",
      "1.0        1\n",
      "16.0       1\n",
      "Name: SLEPTIM1, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax =sns.countplot(x=\"SLEPTIM1\", data=alldf_new)\n",
    "ax.tick_params(axis='x', colors='red')  # Change x-axis label color to red\n",
    "ax.tick_params(axis='y', colors='red')  # Change y-axis label color to red\n",
    "\n",
    "plt.title(\"Diabetes Distribution\")\n",
    "\n",
    "print(alldf_new['SLEPTIM1'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_plots = {\n",
    "    \"_RACE\": {\n",
    "        \"labels\": {\n",
    "            1: \"White\",\n",
    "            2: \"Black\",\n",
    "            3: \"Am. Indian\",\n",
    "            4: \"Asian\",\n",
    "            5: \"Pacific\",\n",
    "            6: \"Other\",\n",
    "            7: \"Multiracial\",\n",
    "            8: \"Hispanic\",\n",
    "            9: \"Not Sure\",\n",
    "        },\n",
    "        \"figsize\": None,\n",
    "    },\n",
    "    \"SEX\": {\"labels\": {1: \"Male\", 2: \"Female\"}, \"figsize\": None},\n",
    "    \"_STATE\": {\"labels\": None, \"figsize\": (12, 5)},\n",
    "    \"DRVISITS\": {\"labels\": None, \"figsize\": (12, 5)},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def graph(variable, df=alldf_new, figsize=None, labels=None, plot_type='bar', title=None, colors=None):\n",
    "    \n",
    "    \n",
    "    # this is to enhance the function for clarity of usage.\n",
    "    if df.empty or variable not in df.columns:\n",
    "        raise ValueError(\"DataFrame is empty or specified variable not found in DataFrame.\")\n",
    "\n",
    "    var_df = df.copy()\n",
    "\n",
    "    if labels:\n",
    "        var_df[variable] = df[variable].replace(labels)\n",
    "\n",
    "    grouped_data = var_df.groupby(variable)[\"DIABETE3\"].value_counts(normalize=True).unstack()\n",
    "\n",
    "    # Plotting\n",
    "    if not figsize:\n",
    "        figsize = (8, 6)  # Default figsize\n",
    "\n",
    "    if not title:\n",
    "        title = f\"Diabetes Distribution over {variable}\"\n",
    "\n",
    "    if not colors:\n",
    "        colors = ['skyblue','yellow']  # Default color\n",
    "\n",
    "    ax = grouped_data.plot(kind=plot_type, figsize=figsize, title=title, color=colors)\n",
    "\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in variables:\n",
    "    if v in custom_plots:\n",
    "        graph(\n",
    "            v,\n",
    "            figsize=custom_plots[v].get(\"figsize\"),\n",
    "            labels=custom_plots[v].get(\"labels\"),\n",
    "        )\n",
    "    else:\n",
    "        graph(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c. Justify your variable selection\n",
    "\n",
    "Don't necessarily know how to do this part yet at this point. I just chose all the variables. Is there another way I should answer this question and choose my variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation:**\n",
    "\n",
    "- If a correlation value is negative or very low, it indicates a weak relationship with DIABETE3. For example, _RACE has a negative value, suggesting a weak relationship, so consider dropping _RACE as a variable. However, later on, it's observed that all independent variables have a weak relationship to the target, so it's wiser to instead observe relationships to DIABETE3 with combined features.\n",
    "\n",
    "- A negative relationship implies an inverse correlation, while a positive relationship means that as one variable increases, the other also increases. If there's no relationship, there isn't a set rule for what happens to the other variable.\n",
    "\n",
    "- The range of the correlation coefficient (\\(r\\)) is -1 to 1, where:\n",
    "  - \\(r = 1\\): Perfect positive relationship\n",
    "  - \\(0.5 < r < 1\\): Strong positive relationship\n",
    "  - \\(0 < r \\leq 0.5\\): Weak positive relationship\n",
    "  - \\(-0.5 \\leq r < 0\\): Weak negative relationship\n",
    "  - \\(-1 < r < -0.5\\): Strong negative relationship\n",
    "  - \\(r = -1\\): Perfect negative relationship\n",
    "  - \\(r = 0\\): No relationship\n",
    "\n",
    "- A variable can **only** have a perfect relationship to another variable if compared to itself.\n",
    "\n",
    "- When using `corr()`, all variables need to be the same length. It cannot work on categorical and numeric types simultaneously. Therefore, run `corr()` when all features are of the same type.\n",
    "\n",
    "*Refer to the correlation formula for a detailed understanding.*\n",
    "\n",
    "**Population Analysis:**\n",
    "\n",
    "- The dataset has a relatively small number of variables compared to the number of entries.\n",
    "\n",
    "- Overfitting occurs when there are few variables and many entries, leading the model to capture noise instead of true patterns. Underfitting is the opposite, where the model is too simple to capture the underlying patterns.\n",
    "\n",
    "- Conduct population analysis to identify variables with weak relationships to the target variable (DIABETE3). In a large dataset, it's acceptable to drop these variables to reduce bias and improve model performance.\n",
    "\n",
    "- Building the model with only the most significant variables helps prevent overfitting and enhances the model's generalizability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DIABETE3', 'EMPLOY1', 'GENHLTH', '_AGEG5YR']\n",
      " 4\n",
      "['CVDCRHD4', 'CHCKIDNY', 'USEEQUIP', 'ADDEPEV2', 'CHILDREN', 'CHECKUP1', 'INCOME2']\n",
      " 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CVDCRHD4',\n",
       " 'CHCKIDNY',\n",
       " 'USEEQUIP',\n",
       " 'ADDEPEV2',\n",
       " 'CHILDREN',\n",
       " 'CHECKUP1',\n",
       " 'INCOME2',\n",
       " 'DIABETE3',\n",
       " 'EMPLOY1',\n",
       " 'GENHLTH',\n",
       " '_AGEG5YR']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame and 'target_variable' is the variable you want to compare correlations with\n",
    "target_variables= 'DIABETE3'\n",
    "\n",
    "# Calculate correlations with the target variable\n",
    "correlations = alldf_new.corr()[target_variables]\n",
    "\n",
    "# Select variables where the correlation is greater than 0.2 or less than -0.1\n",
    "goodPositive_Selected_variables = correlations[(correlations > 0.2) ].index.tolist()\n",
    "print(f\"{goodPositive_Selected_variables}\\n {len(goodPositive_Selected_variables)}\") # these are good variables to use.\n",
    "\n",
    "goodNegative_Selected_Variables = correlations[(correlations <-0.1) ].index.tolist()\n",
    "print(f\"{goodNegative_Selected_Variables}\\n {len(goodNegative_Selected_Variables)}\") # these are good variables to use.\n",
    "\n",
    "\n",
    "goodNegative_Selected_Variables.extend(goodPositive_Selected_variables)\n",
    "goodNegative_Selected_Variables\n",
    "\n",
    "desiredVars =goodNegative_Selected_Variables\n",
    "desiredVars # variables of interest is now contained herein\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.EMPLOY1: Employment status can instigate diabete3 eg: a person without any source of income can be worried, consequently have HBB which may lead to diabete3\n",
    "\n",
    "2.GENHLTH: Awareness of a person's general status can boost health confidence thereby eliminating health worries which may lead to HBB/diabete3.\n",
    "\n",
    "3. _AGEG5YR: A person's age is a factor for being diabetic \n",
    "All the above are positive relationship which means, increase in one leads leads to increase in the other though not in a consistent basis as the relationship is not strong.\n",
    "\n",
    "1. CVDCRHD4: History of coronary heart disease could also contribute to a person being diabetic.\n",
    "2. CHCKIDNY:  History of kidney disease could also contribute to a person being diabetic.\n",
    "3.'USEEQUIP: Health condition that makes a person use special equipment could make the person diabetic\n",
    "\n",
    "4. ADDEPEV2: Depressive conditions could make a person diabetic\n",
    "\n",
    "5. 'CHILDREN: The number of children a partent have may be factor for diabete3\n",
    "\n",
    "6.CHECKUP1: Medical checkup intervals could also be used to study diabete3.\n",
    "\n",
    "7. INCOME2: A person's income status/level may explain diabete3.\n",
    "\n",
    "Note: All the above factors cannot independently explain diabete3 . However, they have understood relationship with diabete3.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(35, 20))\n",
    "\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(corr, annot=True, linewidths=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corr[\"DIABETE3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The independent variables exhibit a modest association with diabetes, as indicated by correlation coefficients (r) falling within the range of -.5<=r<0 or 0<r<=0.5. Consequently, it becomes essential to evaluate the collective relationships among the features of the independent variables in connection to diabetes. None of the variables independently can explain the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering  \n",
    "creating new features from highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = alldf_new.corr()\n",
    "def get_correlated_features(feature=\"DIABETE3\",corr = cor):\n",
    "    \"\"\"\n",
    "    Given a feature name, get the features with a strong and weak or negligible correlation to it.\n",
    "    \"\"\"\n",
    "\n",
    "    correlation_dict = corr[feature]\n",
    "    weak_dict, strong_dict = {}, {}\n",
    "\n",
    "    for f, r in correlation_dict.items():\n",
    "     #   if -0.5 <= r <= 0.5: # the left tail of this condition is not correct by logic.\n",
    "        if -0.5<=r <=0.5: # this is what you intend to do.\n",
    "            weak_dict[f] = r\n",
    "        elif -1 <= r < 1: # no nan or 1 vals. This is very correct\n",
    "            strong_dict[f] = r\n",
    "\n",
    "    weak = sorted(weak_dict.items(), key=lambda x: x[1])\n",
    "    strong = sorted(strong_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return weak, strong\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EMPLOY1', '_AGEG5YR', 0.5309092868535303),\n",
       " ('WEIGHT2', '_BMI5CAT', 0.7446543973565117),\n",
       " ('_AGEG5YR', 'EMPLOY1', 0.5309092868535303),\n",
       " ('_BMI5CAT', 'WEIGHT2', 0.7446543973565117)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_correlations = []\n",
    "\n",
    "for col in alldf_new.columns:\n",
    "    _, strong = get_correlated_features(col)\n",
    "\n",
    "    strong_correlations.extend([(col, f, v) for f, v in strong])\n",
    "\n",
    "strong_correlations \n",
    "''' good exploration. But note that the study is tailored to the correlation of  target\n",
    "variable with every other variables.\n",
    "'''\n",
    "strong_correlations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I derived that the strongest correlations are between the following:\n",
    "- EMPLOY1 and AGEG5YR have a strong positive correlation where r = 0.556\n",
    "- CHILDREN and _AGEG5YR have a strong negative correlation where r = -0.526.\n",
    "- WEIGHT2 and _BMI5CAT have a strong positive correlation where r = 0.751. \n",
    "\n",
    "**Therefore, these are the variables I choose along with the target variable, DIABETE3.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sns.countplot is great for plotting two categorical variables. \n",
    "- If dodge is set to True, the bars corresponding to different categories of the hue variable will be plotted adjacent to each other. \n",
    "- Example: the graph below for age vs employment, the bars for each color within an age group show the count of individuals with that specific employment status in that age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0.555511 (strong positive correlation)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax =sns.countplot(x=\"_AGEG5YR\", hue=\"EMPLOY1\", data=alldf_new, dodge=False)\n",
    "ax.tick_params(axis='x', colors='red')  # Change x-axis label color to red\n",
    "ax.tick_params(axis='y', colors='red')  # Change y-axis label color to red\n",
    "\n",
    "# sns.set(rc={'xtick.color':'red', 'ytick.color':'red'})\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0.555511 (strong positive correlation)\n",
    " # see if you can interpret this one better than the doged chart above.\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax =sns.countplot(x=\"_AGEG5YR\", hue=\"EMPLOY1\", data=alldf_new, dodge=True)\n",
    "ax.tick_params(axis='x', colors='red')  # Change x-axis label color to red\n",
    "ax.tick_params(axis='y', colors='red')  # Change y-axis label color to red\n",
    "\n",
    "# sns.set(rc={'xtick.color':'red', 'ytick.color':'red'})\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x240d54876a0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 180x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -0.053873 (weak negative correlation)\n",
    "sns.pairplot(alldf_new, x_vars=\"EMPLOY1\", y_vars=\"DRVISITS\", kind ='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Clean the dataset to handle any missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Justify your decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to drop all NA values because those represented BLANK, which corresponds with missing values. Additionally, I decided to get rid of values that correspond to \"refused\" and \"do not know/not sure\" because I felt that simplifying the dataset to only include entries where respondents gave clear answers was important for training my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4a. For building a model, would you rescale any data in this dataset? **How** and **why or why not**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I were using k-nearest neighbors (knn), gradient descent-based algorithms, principal component analysis, or regularization techniques I would rescale since those models/algorithms are sensitive to feature scales. For instance, distance-based algorithms like knn rely on the distance between data points, so a major difference in scale can lead to greater distances which can dominate distance calculations. So rescaling some features could improve convergence and diminish bias amongst features. The way I would rescale is by standardizing or normalizing the data for features with a major range such as WEIGHT2 since pounds can go from 50-999 and similarly kilograms 9000-9998.\n",
    "\n",
    "However, I wouldn't need to rescale if I use a tree-based model such as decision trees, random forests, or gradient boosting methods since they're typically insensitive to features' scales. For example, decision trees rely on feature thresholds, which is impartial to the scale of those features.\n",
    "\n",
    "In my case, I chose to use XGBoosting and also tried regular Gradient Boosting, particularly the classification model version. Therefore, I don't need to rescale as mentioned prior. \n",
    "\n",
    "Nonetheless, I will still address the imbalanced nature of my dataset regardless of the model used since I want to mitigate bias to the majority class. I learned by graphing the diabetes distribution there's an overwhelming number of people without diabetes to those with. To resolve this imbalance, I can perform random or synthetic oversampling methods.\n",
    "\n",
    "Furthermore, for the WEIGHT2 feature, unifying the units to a single metric, such as pounds will help because the model won't recognize the difference between pounds and kilograms. For the target variable DIABETE3, adopting a binary representation where 1 indicates a positive diagnosis of diabetes and 0 signifies the absence of a diabetes diagnosis aligns with my goal of binary classification in the modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5a Build a model to identify risk factors for diabetes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b Explain your choice of model and what it can predict. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5c What metrics would you use to assess performance? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5d For this dataset, how would you know your model is adequate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip show category_encoders # to check if the package exist or not\n",
    "!pip show xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Load dataset\\nfrom sklearn.datasets import load_boston\\nf\\nboston = load_boston()\\ndata = boston.data\\ntarget = boston.target\\n\\n# Split data into train and test sets\\nX_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\\n\\n# Create XGBoost regressor\\nxg_reg = xgb.XGBRegressor(objective =\\'reg:squarederror\\', colsample_bytree = 0.3, learning_rate = 0.1,\\n                max_depth = 5, alpha = 10, n_estimators = 10)\\n\\n# Fit the model\\nxg_reg.fit(X_train, y_train)\\n\\n# Predict on test data\\npreds = xg_reg.predict(X_test)\\n\\n# Evaluate the model\\nrmse = mean_squared_error(y_test, preds, squared=False)\\nprint(\"RMSE:\", rmse)\\n\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "estimators =[('encoder', TargetEncoder()),('clf', XGBClassifier(random_state =8))\n",
    "            ]\n",
    "pipe =Pipeline(steps =estimators)\n",
    "pipe\n",
    "\n",
    "\n",
    "'''\n",
    "# Load dataset\n",
    "from sklearn.datasets import load_boston\n",
    "f\n",
    "boston = load_boston()\n",
    "data = boston.data\n",
    "target = boston.target\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create XGBoost regressor\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "# Fit the model\n",
    "xg_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# separate target and independent variables\n",
    "y_resample= alldf_tmp[\"DIABETE3\"] \n",
    "X_resample = alldf_tmp.drop(columns=\"DIABETE3\") \n",
    "alldf_tmp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y= alldf_new['DIABETE3']\n",
    "X = alldf_new.drop(columns = 'DIABETE3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE (Synthetic Minority Over-sampling Technique) from the imbalanced-learn library to address class imbalance in a dataset. SMOTE is commonly used for oversampling the minority class to balance class distribution in classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PERSONID\n",
       "355467    3.0\n",
       "117235    3.0\n",
       "268614    3.0\n",
       "332821    3.0\n",
       "348522    3.0\n",
       "         ... \n",
       "447307    3.0\n",
       "401134    3.0\n",
       "227725    3.0\n",
       "394805    3.0\n",
       "168122    3.0\n",
       "Name: DIABETE3, Length: 5000, dtype: category\n",
       "Categories (6, float64): [1.0, 2.0, 3.0, 4.0, 7.0, 9.0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldf_tmp[\"DIABETE3\"].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where I have the challenge please"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8372/1533680757.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msmote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mX_resample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_resample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Downloads\\Anaconda-\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda-\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    110\u001b[0m         )\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         y_ = (\n",
      "\u001b[1;32m~\\Downloads\\Anaconda-\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[0mnns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[0;32m    366\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda-\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    820\u001b[0m         )\n\u001b[0;32m    821\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_pairwise_distances_reductions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m             results = ArgKmin.compute(\n\u001b[0m\u001b[0;32m    823\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m                 \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda-\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[0;32m    257\u001b[0m         \"\"\"\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             return ArgKmin64.compute(\n\u001b[0m\u001b[0;32m    260\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\u001b[0m in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda-\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36mthreadpool_limits\u001b[1;34m(limits, user_api)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontroller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreadpool_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda-\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, limits, user_api)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_threadpool_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda-\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_set_threadpool_limits\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         modules = _ThreadpoolInfo(prefixes=self._prefixes,\n\u001b[0m\u001b[0;32m    269\u001b[0m                                   user_api=self._user_api)\n\u001b[0;32m    270\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda-\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_modules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_if_incompatible_openmp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda-\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_load_modules\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_dyld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"win32\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_enum_process_module_ex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_dl_iterate_phdr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda-\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_find_modules_with_enum_process_module_ex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m                 \u001b[1;31m# Store the module if it is supported and selected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_module_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mkernel_32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCloseHandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_process\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda-\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_make_module_from_path\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefixes\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0muser_api\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[0mmodule_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule_class\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m                 \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda-\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal_api\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynlib\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_RTLD_NOLOAD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_threads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_num_threads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_extra_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda-\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36mget_version\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    644\u001b[0m                              lambda: None)\n\u001b[0;32m    645\u001b[0m         \u001b[0mget_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"OpenBLAS\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# address imbalance in the dataset\n",
    "\n",
    "y_resample = alldf_new[\"DIABETE3\"]\n",
    "X_resample= alldf_new.drop(columns = \"DIABETE3\")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_resample, y_resample = smote.fit_resample(X_resample, y_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate example data (you may have your own dataset)\n",
    "X, y = make_classification(n_classes=2, class_sep=2, weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0, n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=42)\n",
    "\n",
    "# Split the data into train and test sets (you may already have your train/test split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE only on the training data to avoid data leakage\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Now, continue with your machine learning workflow using X_train_resampled and y_train_resampled\n",
    "# (e.g., train your model on the resampled data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8372/4090613055.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# cross validation version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mkf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mavg_model_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_model_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "# cross validation version\n",
    "kf = KFold(n_splits=5)\n",
    "avg_model_scores = np.mean(cross_val_score(model, X, y, cv=kf))\n",
    "print(avg_model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = model.feature_importances_\n",
    "for feature, importance in sorted(zip(X.columns, feature_importances), key=lambda x: x[1], reverse=True):\n",
    "  print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Using these data, what are some identifiable risk factors for diabetes? How do you know? Explain as if you were reporting the results to a non-technical stakeholder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important features are \n",
    "\n",
    "GENHLTH: 0.16922499239444733\n",
    "_TOTINDA: 0.07415896654129028\n",
    "CHILDREN: 0.07380124181509018\n",
    "_BMI5CAT: 0.07154451310634613\n",
    "BLIND: 0.05338083207607269\n",
    "CVDCRHD4: 0.050223458558321\n",
    "\n",
    "The least important are:\n",
    "\n",
    "WEIGHT2: 0.010020529851317406\n",
    "PERSONID: 0.00973158422857523\n",
    "MARITAL: 0.009483946487307549\n",
    "_STATE: 0.008029725402593613\n",
    "EXERANY2: 0.0\n",
    "HLTHPLN1: 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
